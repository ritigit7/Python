{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.duplicated().sum()#find duplicate \n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: count, dtype: int64\n",
      "Gender\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: count, dtype: int64\n",
      "Geography\n",
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Exited\"].value_counts())\n",
    "print(df[\"Gender\"].value_counts())\n",
    "print(df[\"Geography\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,columns=[\"Geography\",\"Gender\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1              False   \n",
       "1                  1        112542.58       0              False   \n",
       "2                  0        113931.57       1              False   \n",
       "3                  0         93826.63       0              False   \n",
       "4                  1         79084.10       0              False   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0              False   \n",
       "9996               1        101699.77       0              False   \n",
       "9997               1         42085.58       1              False   \n",
       "9998               0         92888.52       1               True   \n",
       "9999               0         38190.78       0              False   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0               False        False  \n",
       "1                True        False  \n",
       "2               False        False  \n",
       "3               False        False  \n",
       "4                True        False  \n",
       "...               ...          ...  \n",
       "9995            False         True  \n",
       "9996            False         True  \n",
       "9997            False        False  \n",
       "9998            False         True  \n",
       "9999            False        False  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=[\"Exited\"])\n",
    "y=df[\"Exited\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.23676019,  0.29353011, -1.04191108, ..., -0.57881318,\n",
       "         -0.57388544, -1.09578666],\n",
       "        [ 0.61523625, -0.46925336,  1.03271175, ...,  1.72767315,\n",
       "         -0.57388544,  0.9125864 ],\n",
       "        [-1.11260401, -0.85064509,  0.3411708 , ...,  1.72767315,\n",
       "         -0.57388544,  0.9125864 ],\n",
       "        ...,\n",
       "        [ 0.22207499,  0.57957391,  1.37848222, ..., -0.57881318,\n",
       "         -0.57388544, -1.09578666],\n",
       "        [ 0.12895785,  0.00748631,  1.03271175, ..., -0.57881318,\n",
       "         -0.57388544, -1.09578666],\n",
       "        [ 1.16359273,  0.29353011,  0.3411708 , ...,  1.72767315,\n",
       "         -0.57388544,  0.9125864 ]]),\n",
       " array([[-1.,  1., -1., -1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1., -1.,  1.,  1., -1.,  0., -1., -1.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)\n",
    "\n",
    "X_train_scaled,X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 3)                 36        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40 (160.00 Byte)\n",
      "Trainable params: 40 (160.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model=Sequential()\n",
    "#input dimention=11\n",
    "model.add(Dense(3,activation=\"sigmoid\",input_dim=11))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\python programs\\All\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From d:\\python programs\\All\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "313/313 [==============================] - 3s 2ms/step - loss: 0.5364\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.4779\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4518\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4383\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4312\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4270\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 0s 2ms/step - loss: 0.4242\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4222\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4204\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4188\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4174\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4161\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4149\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4138\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4129\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4121\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4114\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4107\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4102\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x211f8590ed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='Adam')\n",
    "model.fit(X_train_scaled,y_train,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1199138],\n",
       "        [-1.8049767],\n",
       "        [-1.655806 ]], dtype=float32),\n",
       " array([-0.21143462], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()\n",
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.29033172],\n",
       "       [0.10202656]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From d:\\python programs\\All\\.venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.4102 - accuracy: 0.8318 - val_loss: 0.4049 - val_accuracy: 0.8270\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4097 - accuracy: 0.8327 - val_loss: 0.4049 - val_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4094 - accuracy: 0.8335 - val_loss: 0.4049 - val_accuracy: 0.8295\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4090 - accuracy: 0.8345 - val_loss: 0.4046 - val_accuracy: 0.8305\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4088 - accuracy: 0.8338 - val_loss: 0.4045 - val_accuracy: 0.8305\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4085 - accuracy: 0.8342 - val_loss: 0.4044 - val_accuracy: 0.8305\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4082 - accuracy: 0.8341 - val_loss: 0.4043 - val_accuracy: 0.8305\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.8358 - val_loss: 0.4041 - val_accuracy: 0.8305\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4078 - accuracy: 0.8350 - val_loss: 0.4039 - val_accuracy: 0.8305\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4075 - accuracy: 0.8362 - val_loss: 0.4038 - val_accuracy: 0.8315\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8366 - val_loss: 0.4037 - val_accuracy: 0.8310\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4071 - accuracy: 0.8353 - val_loss: 0.4035 - val_accuracy: 0.8305\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8366 - val_loss: 0.4033 - val_accuracy: 0.8305\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4067 - accuracy: 0.8363 - val_loss: 0.4033 - val_accuracy: 0.8310\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8367 - val_loss: 0.4031 - val_accuracy: 0.8310\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4065 - accuracy: 0.8371 - val_loss: 0.4029 - val_accuracy: 0.8305\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8358 - val_loss: 0.4029 - val_accuracy: 0.8310\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8361 - val_loss: 0.4028 - val_accuracy: 0.8305\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4060 - accuracy: 0.8366 - val_loss: 0.4026 - val_accuracy: 0.8310\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4059 - accuracy: 0.8357 - val_loss: 0.4025 - val_accuracy: 0.8310\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8358 - val_loss: 0.4024 - val_accuracy: 0.8310\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4056 - accuracy: 0.8363 - val_loss: 0.4024 - val_accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4055 - accuracy: 0.8367 - val_loss: 0.4023 - val_accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4054 - accuracy: 0.8370 - val_loss: 0.4023 - val_accuracy: 0.8305\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4053 - accuracy: 0.8365 - val_loss: 0.4023 - val_accuracy: 0.8290\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4051 - accuracy: 0.8366 - val_loss: 0.4022 - val_accuracy: 0.8285\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4051 - accuracy: 0.8377 - val_loss: 0.4021 - val_accuracy: 0.8285\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.8378 - val_loss: 0.4021 - val_accuracy: 0.8275\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4048 - accuracy: 0.8372 - val_loss: 0.4021 - val_accuracy: 0.8295\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4048 - accuracy: 0.8373 - val_loss: 0.4020 - val_accuracy: 0.8285\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4047 - accuracy: 0.8367 - val_loss: 0.4020 - val_accuracy: 0.8285\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8375 - val_loss: 0.4020 - val_accuracy: 0.8290\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4045 - accuracy: 0.8372 - val_loss: 0.4019 - val_accuracy: 0.8270\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8377 - val_loss: 0.4019 - val_accuracy: 0.8280\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4042 - accuracy: 0.8375 - val_loss: 0.4019 - val_accuracy: 0.8280\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4042 - accuracy: 0.8382 - val_loss: 0.4018 - val_accuracy: 0.8285\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4041 - accuracy: 0.8376 - val_loss: 0.4019 - val_accuracy: 0.8280\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4041 - accuracy: 0.8370 - val_loss: 0.4018 - val_accuracy: 0.8280\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4039 - accuracy: 0.8373 - val_loss: 0.4018 - val_accuracy: 0.8275\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4039 - accuracy: 0.8372 - val_loss: 0.4018 - val_accuracy: 0.8280\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4038 - accuracy: 0.8381 - val_loss: 0.4018 - val_accuracy: 0.8280\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4037 - accuracy: 0.8368 - val_loss: 0.4019 - val_accuracy: 0.8275\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8367 - val_loss: 0.4018 - val_accuracy: 0.8265\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4035 - accuracy: 0.8361 - val_loss: 0.4019 - val_accuracy: 0.8265\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4035 - accuracy: 0.8370 - val_loss: 0.4019 - val_accuracy: 0.8270\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8371 - val_loss: 0.4018 - val_accuracy: 0.8265\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4033 - accuracy: 0.8366 - val_loss: 0.4019 - val_accuracy: 0.8270\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4033 - accuracy: 0.8363 - val_loss: 0.4020 - val_accuracy: 0.8270\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8373 - val_loss: 0.4020 - val_accuracy: 0.8265\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8370 - val_loss: 0.4020 - val_accuracy: 0.8275\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8361 - val_loss: 0.4020 - val_accuracy: 0.8260\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8366 - val_loss: 0.4020 - val_accuracy: 0.8265\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4028 - accuracy: 0.8361 - val_loss: 0.4020 - val_accuracy: 0.8270\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8373 - val_loss: 0.4021 - val_accuracy: 0.8265\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8361 - val_loss: 0.4021 - val_accuracy: 0.8270\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8370 - val_loss: 0.4021 - val_accuracy: 0.8270\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8371 - val_loss: 0.4022 - val_accuracy: 0.8265\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8372 - val_loss: 0.4023 - val_accuracy: 0.8265\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4023 - accuracy: 0.8360 - val_loss: 0.4025 - val_accuracy: 0.8265\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8376 - val_loss: 0.4024 - val_accuracy: 0.8275\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8367 - val_loss: 0.4025 - val_accuracy: 0.8260\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8370 - val_loss: 0.4025 - val_accuracy: 0.8265\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4020 - accuracy: 0.8367 - val_loss: 0.4025 - val_accuracy: 0.8265\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4019 - accuracy: 0.8371 - val_loss: 0.4025 - val_accuracy: 0.8265\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8380 - val_loss: 0.4026 - val_accuracy: 0.8265\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8375 - val_loss: 0.4026 - val_accuracy: 0.8260\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8363 - val_loss: 0.4027 - val_accuracy: 0.8270\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8367 - val_loss: 0.4027 - val_accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8370 - val_loss: 0.4028 - val_accuracy: 0.8260\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8372 - val_loss: 0.4028 - val_accuracy: 0.8255\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4013 - accuracy: 0.8370 - val_loss: 0.4029 - val_accuracy: 0.8255\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8371 - val_loss: 0.4029 - val_accuracy: 0.8255\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8378 - val_loss: 0.4030 - val_accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8377 - val_loss: 0.4031 - val_accuracy: 0.8265\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8376 - val_loss: 0.4030 - val_accuracy: 0.8265\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8381 - val_loss: 0.4031 - val_accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8372 - val_loss: 0.4032 - val_accuracy: 0.8270\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4006 - accuracy: 0.8378 - val_loss: 0.4033 - val_accuracy: 0.8275\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8386 - val_loss: 0.4033 - val_accuracy: 0.8260\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8381 - val_loss: 0.4033 - val_accuracy: 0.8265\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8377 - val_loss: 0.4033 - val_accuracy: 0.8275\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8378 - val_loss: 0.4034 - val_accuracy: 0.8270\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8372 - val_loss: 0.4034 - val_accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8371 - val_loss: 0.4035 - val_accuracy: 0.8265\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8386 - val_loss: 0.4035 - val_accuracy: 0.8260\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8377 - val_loss: 0.4036 - val_accuracy: 0.8265\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8381 - val_loss: 0.4038 - val_accuracy: 0.8255\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8381 - val_loss: 0.4039 - val_accuracy: 0.8255\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8375 - val_loss: 0.4038 - val_accuracy: 0.8265\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3995 - accuracy: 0.8373 - val_loss: 0.4038 - val_accuracy: 0.8255\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3994 - accuracy: 0.8371 - val_loss: 0.4039 - val_accuracy: 0.8265\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3993 - accuracy: 0.8377 - val_loss: 0.4039 - val_accuracy: 0.8255\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3993 - accuracy: 0.8372 - val_loss: 0.4038 - val_accuracy: 0.8260\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3991 - accuracy: 0.8378 - val_loss: 0.4037 - val_accuracy: 0.8260\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3990 - accuracy: 0.8372 - val_loss: 0.4040 - val_accuracy: 0.8265\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.8366 - val_loss: 0.4040 - val_accuracy: 0.8275\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3989 - accuracy: 0.8363 - val_loss: 0.4039 - val_accuracy: 0.8275\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3988 - accuracy: 0.8363 - val_loss: 0.4040 - val_accuracy: 0.8270\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3987 - accuracy: 0.8363 - val_loss: 0.4040 - val_accuracy: 0.8270\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8371 - val_loss: 0.4039 - val_accuracy: 0.8270\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "history=model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4102025330066681,\n",
       "  0.40972015261650085,\n",
       "  0.4093679189682007,\n",
       "  0.4090093970298767,\n",
       "  0.4087745249271393,\n",
       "  0.40845853090286255,\n",
       "  0.40820205211639404,\n",
       "  0.40798690915107727,\n",
       "  0.4077656865119934,\n",
       "  0.4074631333351135,\n",
       "  0.40727755427360535,\n",
       "  0.40708816051483154,\n",
       "  0.40692272782325745,\n",
       "  0.40674692392349243,\n",
       "  0.4066186547279358,\n",
       "  0.4064652621746063,\n",
       "  0.40622931718826294,\n",
       "  0.4060835540294647,\n",
       "  0.40596044063568115,\n",
       "  0.4058721661567688,\n",
       "  0.40572160482406616,\n",
       "  0.40559718012809753,\n",
       "  0.4055403470993042,\n",
       "  0.4053645730018616,\n",
       "  0.40526512265205383,\n",
       "  0.4051443636417389,\n",
       "  0.4050506055355072,\n",
       "  0.4049655795097351,\n",
       "  0.40483358502388,\n",
       "  0.4047588109970093,\n",
       "  0.4046792685985565,\n",
       "  0.40456855297088623,\n",
       "  0.40449059009552,\n",
       "  0.40438058972358704,\n",
       "  0.40423986315727234,\n",
       "  0.4041901230812073,\n",
       "  0.40413522720336914,\n",
       "  0.4041071832180023,\n",
       "  0.40394511818885803,\n",
       "  0.4038732647895813,\n",
       "  0.40382450819015503,\n",
       "  0.4036526381969452,\n",
       "  0.4035983681678772,\n",
       "  0.4035490155220032,\n",
       "  0.4034666419029236,\n",
       "  0.403380811214447,\n",
       "  0.4032802879810333,\n",
       "  0.40326356887817383,\n",
       "  0.4031386971473694,\n",
       "  0.40306356549263,\n",
       "  0.40298864245414734,\n",
       "  0.4028659462928772,\n",
       "  0.4028417468070984,\n",
       "  0.4027339518070221,\n",
       "  0.40262895822525024,\n",
       "  0.40256330370903015,\n",
       "  0.40248987078666687,\n",
       "  0.40238156914711,\n",
       "  0.40230512619018555,\n",
       "  0.4022493362426758,\n",
       "  0.4021269381046295,\n",
       "  0.4020686745643616,\n",
       "  0.401989221572876,\n",
       "  0.40191495418548584,\n",
       "  0.4017455279827118,\n",
       "  0.40171581506729126,\n",
       "  0.4016428291797638,\n",
       "  0.40155285596847534,\n",
       "  0.4014265239238739,\n",
       "  0.40135592222213745,\n",
       "  0.4012855291366577,\n",
       "  0.40117254853248596,\n",
       "  0.40109533071517944,\n",
       "  0.4010094106197357,\n",
       "  0.4008903503417969,\n",
       "  0.40086567401885986,\n",
       "  0.40079838037490845,\n",
       "  0.400642454624176,\n",
       "  0.4005321264266968,\n",
       "  0.4004770815372467,\n",
       "  0.40037477016448975,\n",
       "  0.4003443121910095,\n",
       "  0.400155246257782,\n",
       "  0.4001704454421997,\n",
       "  0.39995577931404114,\n",
       "  0.399873822927475,\n",
       "  0.3998325765132904,\n",
       "  0.39968132972717285,\n",
       "  0.39962038397789,\n",
       "  0.3995154798030853,\n",
       "  0.39944037795066833,\n",
       "  0.3993217945098877,\n",
       "  0.3992525637149811,\n",
       "  0.39914846420288086,\n",
       "  0.3990384638309479,\n",
       "  0.3989015817642212,\n",
       "  0.3988814949989319,\n",
       "  0.39880234003067017,\n",
       "  0.39865007996559143,\n",
       "  0.39856866002082825],\n",
       " 'accuracy': [0.8318329453468323,\n",
       "  0.8327081799507141,\n",
       "  0.8334583640098572,\n",
       "  0.834458589553833,\n",
       "  0.8338334560394287,\n",
       "  0.8342085480690002,\n",
       "  0.8340834975242615,\n",
       "  0.8358339667320251,\n",
       "  0.8349587321281433,\n",
       "  0.8362090587615967,\n",
       "  0.8365841507911682,\n",
       "  0.8353338241577148,\n",
       "  0.8365841507911682,\n",
       "  0.8363341093063354,\n",
       "  0.836709201335907,\n",
       "  0.8370842933654785,\n",
       "  0.8358339667320251,\n",
       "  0.8360840082168579,\n",
       "  0.8365841507911682,\n",
       "  0.8357089161872864,\n",
       "  0.8358339667320251,\n",
       "  0.8363341093063354,\n",
       "  0.836709201335907,\n",
       "  0.8369592428207397,\n",
       "  0.8364591002464294,\n",
       "  0.8365841507911682,\n",
       "  0.8377094268798828,\n",
       "  0.8378344774246216,\n",
       "  0.8372092843055725,\n",
       "  0.8373343348503113,\n",
       "  0.836709201335907,\n",
       "  0.83745938539505,\n",
       "  0.8372092843055725,\n",
       "  0.8377094268798828,\n",
       "  0.83745938539505,\n",
       "  0.8382095694541931,\n",
       "  0.837584376335144,\n",
       "  0.8369592428207397,\n",
       "  0.8373343348503113,\n",
       "  0.8372092843055725,\n",
       "  0.8380845189094543,\n",
       "  0.836834192276001,\n",
       "  0.836709201335907,\n",
       "  0.8360840082168579,\n",
       "  0.8369592428207397,\n",
       "  0.8370842933654785,\n",
       "  0.8365841507911682,\n",
       "  0.8363341093063354,\n",
       "  0.8373343348503113,\n",
       "  0.8369592428207397,\n",
       "  0.8360840082168579,\n",
       "  0.8365841507911682,\n",
       "  0.8360840082168579,\n",
       "  0.8373343348503113,\n",
       "  0.8360840082168579,\n",
       "  0.8369592428207397,\n",
       "  0.8370842933654785,\n",
       "  0.8372092843055725,\n",
       "  0.8359590172767639,\n",
       "  0.837584376335144,\n",
       "  0.836709201335907,\n",
       "  0.8369592428207397,\n",
       "  0.836709201335907,\n",
       "  0.8370842933654785,\n",
       "  0.8379594683647156,\n",
       "  0.83745938539505,\n",
       "  0.8363341093063354,\n",
       "  0.836709201335907,\n",
       "  0.8369592428207397,\n",
       "  0.8372092843055725,\n",
       "  0.8369592428207397,\n",
       "  0.8370842933654785,\n",
       "  0.8378344774246216,\n",
       "  0.8377094268798828,\n",
       "  0.837584376335144,\n",
       "  0.8380845189094543,\n",
       "  0.8372092843055725,\n",
       "  0.8378344774246216,\n",
       "  0.8385846614837646,\n",
       "  0.8380845189094543,\n",
       "  0.8377094268798828,\n",
       "  0.8378344774246216,\n",
       "  0.8372092843055725,\n",
       "  0.8370842933654785,\n",
       "  0.8385846614837646,\n",
       "  0.8377094268798828,\n",
       "  0.8380845189094543,\n",
       "  0.8380845189094543,\n",
       "  0.83745938539505,\n",
       "  0.8373343348503113,\n",
       "  0.8370842933654785,\n",
       "  0.8377094268798828,\n",
       "  0.8372092843055725,\n",
       "  0.8378344774246216,\n",
       "  0.8372092843055725,\n",
       "  0.8365841507911682,\n",
       "  0.8363341093063354,\n",
       "  0.8363341093063354,\n",
       "  0.8363341093063354,\n",
       "  0.8370842933654785],\n",
       " 'val_loss': [0.4049479365348816,\n",
       "  0.40490639209747314,\n",
       "  0.40485039353370667,\n",
       "  0.4046006500720978,\n",
       "  0.40449413657188416,\n",
       "  0.40437397360801697,\n",
       "  0.4043155908584595,\n",
       "  0.4041222929954529,\n",
       "  0.40387141704559326,\n",
       "  0.4037504196166992,\n",
       "  0.40366026759147644,\n",
       "  0.4034942090511322,\n",
       "  0.4033338129520416,\n",
       "  0.40325549244880676,\n",
       "  0.40309906005859375,\n",
       "  0.40294647216796875,\n",
       "  0.4028598666191101,\n",
       "  0.4027787148952484,\n",
       "  0.4026336669921875,\n",
       "  0.40248289704322815,\n",
       "  0.4024372696876526,\n",
       "  0.40238913893699646,\n",
       "  0.4023142457008362,\n",
       "  0.40226951241493225,\n",
       "  0.4022596776485443,\n",
       "  0.4022364318370819,\n",
       "  0.4021112024784088,\n",
       "  0.4021119177341461,\n",
       "  0.4020548164844513,\n",
       "  0.4020402729511261,\n",
       "  0.4020230174064636,\n",
       "  0.4019613265991211,\n",
       "  0.4019037187099457,\n",
       "  0.40188825130462646,\n",
       "  0.4018714427947998,\n",
       "  0.4018495976924896,\n",
       "  0.4018644392490387,\n",
       "  0.40177270770072937,\n",
       "  0.401833713054657,\n",
       "  0.401780903339386,\n",
       "  0.40184786915779114,\n",
       "  0.4019010365009308,\n",
       "  0.40178734064102173,\n",
       "  0.4019109606742859,\n",
       "  0.4018525183200836,\n",
       "  0.40182483196258545,\n",
       "  0.40189433097839355,\n",
       "  0.4019715189933777,\n",
       "  0.4019704759120941,\n",
       "  0.4019854962825775,\n",
       "  0.40200182795524597,\n",
       "  0.4020427167415619,\n",
       "  0.4020177721977234,\n",
       "  0.40209269523620605,\n",
       "  0.4021225571632385,\n",
       "  0.402130663394928,\n",
       "  0.40217792987823486,\n",
       "  0.40233227610588074,\n",
       "  0.4024650454521179,\n",
       "  0.4024212658405304,\n",
       "  0.40249335765838623,\n",
       "  0.40246453881263733,\n",
       "  0.4024815559387207,\n",
       "  0.40250611305236816,\n",
       "  0.4026064872741699,\n",
       "  0.40262559056282043,\n",
       "  0.40268707275390625,\n",
       "  0.40271657705307007,\n",
       "  0.4027581512928009,\n",
       "  0.40275588631629944,\n",
       "  0.4028809368610382,\n",
       "  0.40292882919311523,\n",
       "  0.40297961235046387,\n",
       "  0.4030708372592926,\n",
       "  0.4030389189720154,\n",
       "  0.40314653515815735,\n",
       "  0.4031654894351959,\n",
       "  0.40334352850914,\n",
       "  0.40327194333076477,\n",
       "  0.4033010005950928,\n",
       "  0.4033319354057312,\n",
       "  0.40341702103614807,\n",
       "  0.4034217596054077,\n",
       "  0.4034636318683624,\n",
       "  0.4035487771034241,\n",
       "  0.40362218022346497,\n",
       "  0.40377193689346313,\n",
       "  0.40388840436935425,\n",
       "  0.4037778377532959,\n",
       "  0.40378960967063904,\n",
       "  0.4038645029067993,\n",
       "  0.40385618805885315,\n",
       "  0.4038293659687042,\n",
       "  0.40370967984199524,\n",
       "  0.40396013855934143,\n",
       "  0.40395453572273254,\n",
       "  0.4038991332054138,\n",
       "  0.40399760007858276,\n",
       "  0.4040162265300751,\n",
       "  0.40394651889801025],\n",
       " 'val_accuracy': [0.8270000219345093,\n",
       "  0.8295000195503235,\n",
       "  0.8295000195503235,\n",
       "  0.8305000066757202,\n",
       "  0.8305000066757202,\n",
       "  0.8305000066757202,\n",
       "  0.8305000066757202,\n",
       "  0.8305000066757202,\n",
       "  0.8305000066757202,\n",
       "  0.8314999938011169,\n",
       "  0.8309999704360962,\n",
       "  0.8305000066757202,\n",
       "  0.8305000066757202,\n",
       "  0.8309999704360962,\n",
       "  0.8309999704360962,\n",
       "  0.8305000066757202,\n",
       "  0.8309999704360962,\n",
       "  0.8305000066757202,\n",
       "  0.8309999704360962,\n",
       "  0.8309999704360962,\n",
       "  0.8309999704360962,\n",
       "  0.8299999833106995,\n",
       "  0.8299999833106995,\n",
       "  0.8305000066757202,\n",
       "  0.8289999961853027,\n",
       "  0.828499972820282,\n",
       "  0.828499972820282,\n",
       "  0.8274999856948853,\n",
       "  0.8295000195503235,\n",
       "  0.828499972820282,\n",
       "  0.828499972820282,\n",
       "  0.8289999961853027,\n",
       "  0.8270000219345093,\n",
       "  0.828000009059906,\n",
       "  0.828000009059906,\n",
       "  0.828499972820282,\n",
       "  0.828000009059906,\n",
       "  0.828000009059906,\n",
       "  0.8274999856948853,\n",
       "  0.828000009059906,\n",
       "  0.828000009059906,\n",
       "  0.8274999856948853,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8270000219345093,\n",
       "  0.8264999985694885,\n",
       "  0.8270000219345093,\n",
       "  0.8270000219345093,\n",
       "  0.8264999985694885,\n",
       "  0.8274999856948853,\n",
       "  0.8259999752044678,\n",
       "  0.8264999985694885,\n",
       "  0.8270000219345093,\n",
       "  0.8264999985694885,\n",
       "  0.8270000219345093,\n",
       "  0.8270000219345093,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8274999856948853,\n",
       "  0.8259999752044678,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8259999752044678,\n",
       "  0.8270000219345093,\n",
       "  0.8259999752044678,\n",
       "  0.8259999752044678,\n",
       "  0.8255000114440918,\n",
       "  0.8255000114440918,\n",
       "  0.8255000114440918,\n",
       "  0.8270000219345093,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8264999985694885,\n",
       "  0.8270000219345093,\n",
       "  0.8274999856948853,\n",
       "  0.8259999752044678,\n",
       "  0.8264999985694885,\n",
       "  0.8274999856948853,\n",
       "  0.8270000219345093,\n",
       "  0.8259999752044678,\n",
       "  0.8264999985694885,\n",
       "  0.8259999752044678,\n",
       "  0.8264999985694885,\n",
       "  0.8255000114440918,\n",
       "  0.8255000114440918,\n",
       "  0.8264999985694885,\n",
       "  0.8255000114440918,\n",
       "  0.8264999985694885,\n",
       "  0.8255000114440918,\n",
       "  0.8259999752044678,\n",
       "  0.8259999752044678,\n",
       "  0.8264999985694885,\n",
       "  0.8274999856948853,\n",
       "  0.8274999856948853,\n",
       "  0.8270000219345093,\n",
       "  0.8270000219345093,\n",
       "  0.8270000219345093]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x211fcdd85d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
